{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blueprint Design\n",
    "## Package Import and Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest, f_regression, f_classif\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, f1_score, plot_roc_curve, confusion_matrix, \\\n",
    "ConfusionMatrixDisplay, brier_score_loss, accuracy_score\n",
    "\n",
    "from datetime import date\n",
    "import scorecardpy as sc\n",
    "\n",
    "# Some configuration of the plots we will create later\n",
    "%matplotlib inline  \n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import shap\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncation\n",
    "truncate_item_price = True\n",
    "truncate_delivery_days = False\n",
    "truncate_age = False\n",
    "cut_age = True\n",
    "\n",
    "# imputation\n",
    "numeric_imputer_strategy =  'median' # 'median', 'most_frequent', 'constant' 'mean'\n",
    "numeric_standard_scaler_mean = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define Methods and Wrap them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df, known_data:bool, truncate_delivery_days:bool, truncate_item_price:bool, truncate_age:bool, cut_age:bool):\n",
    "    # change object variables to datatype category\n",
    "    # change numeric variables from float64 to float32 (reduce memory consumption)\n",
    "    # change feature return to boolean (2 categories)\n",
    "    # change dates to the datetime datatype 'datetime64[ns]'\n",
    "    df = transform_columns(df, known_data)\n",
    "    \n",
    "    # via (df['delivery_date'] - df['order_date']).dt.days\n",
    "    df = add_delivery_days(df)\n",
    "\n",
    "    if truncate_delivery_days:\n",
    "        print('truncate_delivery_days')\n",
    "        # via outlier_truncation(df['delivery_days'])\n",
    "        # # Define upper/lower bound\n",
    "        # # upper = x.quantile(0.75) + factor*IQR\n",
    "        # # lower = x.quantile(0.25) - factor*IQR\n",
    "        df = remove_delivery_days_outliers(df)\n",
    "    \n",
    "    # via df['delivery_date'].apply(lambda x: False if pd.isnull(x) else True)\n",
    "    df = add_delivery_date_missing(df)\n",
    "\n",
    "    # year<2016 is all 1994, which is suspicious\n",
    "    # via df['delivery_date'].apply(lambda x: True if x.year < 2016 else False)\n",
    "    df = add_delivery_date_1994_marker(df)\n",
    "\n",
    "    # via df.loc[df['delivery_date'].dt.year < 2016,['delivery_days']] = np.nan\n",
    "    df = set_delivery_date_1994_to_nan(df)\n",
    "    \n",
    "    # via df['brand_id'].apply(lambda x: (df['brand_id'] == x).sum())\n",
    "    df = add_brand_id_count(df)\n",
    "\n",
    "    # via df['item_id'].apply(lambda x: (df['item_id'] == x).sum())\n",
    "    df = add_item_id_count(df)\n",
    "\n",
    "    # set it all to lowercase and correct some spelling error\n",
    "    # then via df['item_color'].apply(lambda x: (df['item_color'] == x).sum())\n",
    "    df = add_item_color_count(df)\n",
    "    \n",
    "    # a practical summary for retailing size:\n",
    "    # sizes_dict = {\n",
    "    #     '84': 'xxs', '104': 's', '110': 's', '116': 's', '122': 'm', '128': 'm',\n",
    "    #     '134': 'l', '140': 'l', '148': 'xl', '152': 'xl', '164': 'xxl', '170': 'xxl',\n",
    "    #     '176': 'xxxl', '18': 'xs', '19': 's', '20': 's', '21': 'm', '22': 'm', '23': 'l',\n",
    "    #     '24':  'xl', '25': 'xs', '26': 's', '27': 's', '28': 'm', '29': 'm',  '30': 'l',\n",
    "    #     '31': 'l', '32': 'xl', '33': 'xxl', '34': 'xxs', '35': 'xs', '36': 'xs', '36+': 's',\n",
    "    #     '37': 's', '37+': 's', '38': 's', '38+': 's', '39': 'm', '39+': 'm', '40': 'm',\n",
    "    #     '40+': 'm', '41': 'm', '41+' : 'm', '42': 'l', '42+': 'l', '43': 'l', '43+': 'l',\n",
    "    #     '44': 'l', '44+' : 'xl', '45' : 'xl', '45+': 'xl', '46': 'xl', '46+' : 'xl',\n",
    "    #     '47' : 'xl', '48': 'xl', '49': 'xl', '50': 'xxl', '52': 'xxl', '54': 'xxl',\n",
    "    #     '56': 'xxl', '58': 'xxl', 0: 'xxs', '1': 'xxs', '2': 'xxs', '2+': 'xxs', '3' : 'xxs',\n",
    "    #     '3+': 'xs', '4':  'xs', '4+': 'xs', '5': 'xs', '5+':'xs', '6':'s', '6+':'s',\n",
    "    #     '7':'s', '7+':'m', '8':'m', '8+':'m', '9': 'l', '9+': 'l', '10': 'l', '10+': 'xl',\n",
    "    #     '11': 'xl', '11+': 'xl', '12': 'xl', '12+': 'xxl', '13': 'xxl', '14': 'xxl',\n",
    "    #     36: 'xxs', 38: 'xs', 40: 's', 42: 'm', 44: 'l', 46: 'xl', 48: 'xxl',\n",
    "    #     '3132': 'xxs', '3332': 'xs', '3432': 'xs', '3632': 's', '3832': 'm', '3634': 'l',\n",
    "    #     '3834': 'xl', '4032': 'xl', '4034': 'xxl', '4232': 'xxxl', '80': 'xs', '85': 's',\n",
    "    #     '90': 'm', '95': 'l', '100': 'xl', '105': 'xxl'\n",
    "    # }\n",
    "    df = convert_item_sizes(df)\n",
    "\n",
    "    if truncate_item_price:\n",
    "        print('truncate_price_size')\n",
    "        # via outlier_truncation(df['item_price'])\n",
    "        df = truncate_item_price_outliers(df)\n",
    "\n",
    "    # via df['user_dob'].apply(calculate_age)\n",
    "    # today = date.today()\n",
    "    # return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "    df = add_age(df)\n",
    "\n",
    "    if truncate_age:\n",
    "        print('truncate_age')\n",
    "        # via outlier_truncation(df['age'])\n",
    "        df = truncate_age_outliers(df)\n",
    "    if cut_age:\n",
    "        print('cut_age')\n",
    "        # via df.loc[df['age'] > 95,'age'] = np.nan\n",
    "        df = cut_age_outliers(df)\n",
    "    \n",
    "    # via df['user_dob'].apply(lambda x: False if pd.isnull(x) else True)\n",
    "    df = add_dob_missing(df)\n",
    "\n",
    "    # via df['been_member_for'] = (df['order_date']-df['user_reg_date'] ).dt.days\n",
    "    df = add_been_member_for(df)\n",
    "\n",
    "    # labels = ['fresh_member', 'new_member', 'member', 'old_member']\n",
    "    # cut_bins = [-5, 150, 300, 450, 1000]\n",
    "    # via df['member'] = pd.cut(df['been_member_for'], bins=cut_bins, labels=labels)\n",
    "    df = add_member_category(df)\n",
    "\n",
    "    print(df.info())\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Data Preparation\n",
    "### Load Data and Take a First Glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_known = pd.read_csv('.../BADS_WS2021_known.csv', index_col='order_item_id') \n",
    "df_known.head()\n",
    "# Query some properties of the data\n",
    "print('Dimensionality of the data is {}'.format(df_known.shape))  # .shape returns a tupel\n",
    "print('The data set has {} cases.'.format(df_known.shape[0]))     # we can also index the elements of that tupel\n",
    "print('The total number of elements is {}.'.format(df_known.size))\n",
    "df_known.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion After Comparison of Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_columns(df_known, known_data:bool):\n",
    "    # change object variables to datatype category\n",
    "    df_known['item_size'] = df_known['item_size'].astype('category')\n",
    "    df_known['item_color'] = df_known['item_color'].astype('category')\n",
    "    df_known['user_title'] = df_known['user_title'].astype('category')\n",
    "    df_known['user_state'] = df_known['user_state'].astype('category')\n",
    "    # change all numeric variables from float64 to float32 to reduce memory consumption\n",
    "    df_known['item_price'] = df_known['item_price'].astype(np.float32)\n",
    "    df_known['item_price'] = df_known['item_price'].apply(lambda x:(\"%.2f\" % round(x, 2)))\n",
    "    df_known['item_price'] = df_known['item_price'].astype(np.float32)\n",
    "    df_known['brand_id'] = df_known['brand_id'].astype(np.int32)\n",
    "    df_known['user_id'] = df_known['user_id'].astype(np.int32)\n",
    "    df_known['item_id'] = df_known['item_id'].astype(np.int32)\n",
    "    if known_data:\n",
    "        # since the feature return has only two values, we convert it to boolean\n",
    "        df_known['return'] = df_known['return'].astype('bool')\n",
    "    # transform all dates to the datetime datatype\n",
    "    df_known['order_date'] = df_known['order_date'].astype('datetime64[ns]')\n",
    "    df_known['delivery_date'] = df_known['delivery_date'].astype('datetime64[ns]')\n",
    "    df_known['user_dob'] = df_known['user_dob'].astype('datetime64[ns]')\n",
    "    df_known['user_reg_date'] = df_known['user_reg_date'].astype('datetime64[ns]')\n",
    "    return df_known\n",
    "\n",
    "df = transform_columns(df, known_data=True)\n",
    "df.info()\n",
    "\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "# Int64Index: 100000 entries, 1 to 100000\n",
    "# Data columns (total 13 columns):\n",
    "#  #   Column         Non-Null Count   Dtype         \n",
    "# ---  ------         --------------   -----         \n",
    "#  0   order_date     100000 non-null  datetime64[ns]\n",
    "#  1   delivery_date  90682 non-null   datetime64[ns]\n",
    "#  2   item_id        100000 non-null  int32         \n",
    "#  3   item_size      100000 non-null  category      \n",
    "#  4   item_color     100000 non-null  category      \n",
    "#  5   brand_id       100000 non-null  int32         \n",
    "#  6   item_price     100000 non-null  float32       \n",
    "#  7   user_id        100000 non-null  int32         \n",
    "#  8   user_title     100000 non-null  category      \n",
    "#  9   user_dob       91275 non-null   datetime64[ns]\n",
    "#  10  user_state     100000 non-null  category      \n",
    "#  11  user_reg_date  100000 non-null  datetime64[ns]\n",
    "#  12  return         100000 non-null  bool          \n",
    "# dtypes: bool(1), category(4), datetime64[ns](4), float32(1), int32(3)\n",
    "# memory usage: 5.8 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Data Description During Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe feature\n",
    "df['order_date'].describe()\n",
    "\n",
    "# Count \"return\" according to \"delivery_date\"\n",
    "## Bar plot\n",
    "df.loc[df[\"delivery_date\"].isna(), ['return']]['return'].value_counts()#.plot(kind=\"bar\")\n",
    "\n",
    "# Head data of multiple features\n",
    "df[['delivery_date', 'delivery_date_missing', 'return']].head()\n",
    "\n",
    "# Cross table\n",
    "pd.crosstab(df['user_title'], df[\"return\"], normalize='index')\n",
    "\n",
    "# Correlation between features\n",
    "df[['delivery_date_missing', 'return']].corr()\n",
    "# Heatmap\n",
    "sns.heatmap(df_corr.corr(),\n",
    "            annot=True);\n",
    "# Boxplot\n",
    "df.boxplot(column='delivery_days')\n",
    "# Violin plot\n",
    "for col in ['order_age','order_age_combine','order_deliver','reg_order']:\n",
    "    plt.figure()\n",
    "    sns.violinplot(x='user_title', y=col, hue='return',\n",
    "                   split=True, inner=\"quart\",\n",
    "                   data= df1, subplots=True)\n",
    "                   \n",
    "# Select specific data according to specific criterion\n",
    "df[df['delivery_days'] < 0]\n",
    "\n",
    "# Categorical feature distribution\n",
    "# Exluding data type float leaves us with the target variable and both categorical variables\n",
    "plt.figure(figsize=(12,6))\n",
    "for i, col in enumerate(df.select_dtypes('category').columns):\n",
    "    plt.figure(i)\n",
    "    a = sns.countplot(x=col, data=df)\n",
    "    a.set_xticklabels(a.get_xticklabels(), rotation=50, ha=\"right\", fontsize=11)  \n",
    "\n",
    "# Stack count plot\n",
    "for i, col in enumerate(['order_date_weekend','delivery_date_weekend',\n",
    "                         'user_reg_date_weekend']):\n",
    "    plt.figure(i)\n",
    "    df1.groupby(['return', col]).size().reset_index().pivot(\n",
    "        columns='return', index=col, values=0).plot(kind='bar',\n",
    "                                                    stacked=True)\n",
    "\n",
    "\n",
    "# WoE (Weight of Evidence, just as an example, it will not be done in this section)\n",
    "bins_been_member_for = sc.woebin(df, y=\"return\", x='been_member_for')\n",
    "\n",
    "sc.woebin_plot(bins_been_member_for)\n",
    "\n",
    "# Numerical feature distribution\n",
    "sns.distplot(df['item_price'])\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(18,12))  # enlarge the figure\n",
    "# We create one histogram for each numeric variable and illustrate how to set the number of bins\n",
    "df['item_price'].hist(bins=20)\n",
    "# or\n",
    "sns.distplot(df['been_member_for'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove correlated features\n",
    "df = df.drop(columns=['brand_id_frequency', 'brand_id_count']) # negative correlation with 'brand_id_woe'\n",
    "\n",
    "# Filter function\n",
    "class filter_binary_target:\n",
    "    def __init__(self, df, target):\n",
    "        self.target = target\n",
    "        self.data_head = df.head()\n",
    "\n",
    "    def auto_filter_binary_target(self):\n",
    "        print('Data must be in a clean pandas DataFrame. Categorical variables must be of data type bool or category. Continuous variables must be int64 or float64.')\n",
    "        data_no_target = df.drop(columns=self.target)\n",
    "        columns = ['Data Type', 'Metric', 'Score']\n",
    "        index = data_no_target.columns\n",
    "        result = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "        for col in data_no_target:\n",
    "            if data_no_target.dtypes[col] == 'bool' or data_no_target.dtypes[col].name == 'category':\n",
    "                result.loc[col, 'Data Type'] = \"discrete\"\n",
    "                result.loc[col, 'Metric'] = \"IV\"\n",
    "                result.loc[col, 'Score'] = self.IV_binary_target(feature=col)\n",
    "\n",
    "            if data_no_target.dtypes[col] == 'int64' or data_no_target.dtypes[col] == 'float64':\n",
    "                result.loc[col, 'Data Type'] = \"continuous\"\n",
    "                result.loc[col, 'Metric'] = \"Fisher\"\n",
    "                result.loc[col, 'Score'] = self.fisher_binary_target(feature=col)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def IV_binary_target(self, feature):  # same code as used above\n",
    "        data = pd.DataFrame()\n",
    "    \n",
    "        data['Count'] = df[feature].value_counts()\n",
    "        data['Bad'] = df.groupby([feature])[self.target].sum()\n",
    "        data['Good'] = data['Count'] - data['Bad']\n",
    "    \n",
    "        data[\"Distribution Bad\"] = data[\"Bad\"] / data[\"Bad\"].sum()\n",
    "        data[\"Distribution Good\"] = data[\"Good\"] / data[\"Good\"].sum()\n",
    "    \n",
    "        data['WOE'] = np.log(data[\"Distribution Good\"] / data[\"Distribution Bad\"])\n",
    "        data.replace({\"WOE\": {np.inf: 0, -np.inf: 0}})\n",
    "\n",
    "        data[\"IV\"] = data[\"WOE\"] * (data[\"Distribution Good\"] - data[\"Distribution Bad\"])\n",
    "\n",
    "        iv = data[\"IV\"].sum()\n",
    "\n",
    "        return iv\n",
    "\n",
    "    def fisher_binary_target(self, feature):\n",
    "        mu_0 = df.groupby(df[self.target])[feature].mean()[0]\n",
    "        mu_1 = df.groupby(df[self.target])[feature].mean()[1]\n",
    "        var_0 = df.groupby(df[self.target])[feature].var()[0]\n",
    "        var_1 = df.groupby(df[self.target])[feature].var()[1]\n",
    "\n",
    "        num = abs(mu_0 - mu_1)\n",
    "        den = (var_0 + var_1) ** 0.5\n",
    "        score = num/den\n",
    "    \n",
    "        return score\n",
    "\n",
    "    def pearson(self, feature):  # since our target is binary, we actually don't need this. However, if you would like to expand this class, you can use this code\n",
    "        mean_feature = df[feature].mean()\n",
    "        mean_target = df[self.target].mean()\n",
    "        num = ((df[feature] - mean_feature)*(df[self.target] - mean_target)).sum()\n",
    "        den = (((df[feature] - mean_feature)**2).sum() * ((df[self.target] - mean_target)**2).sum()) ** .5\n",
    "        rho = num/den\n",
    "        return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline construction\n",
    "### Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only specified columns\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]\n",
    "        \n",
    "# Drop only specified columns, it will be used after completely preprocessing the data before traing model\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, drop_list):\n",
    "        self.drop_list = drop_list\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        df = X.drop(list(self.drop_list), axis=1)\n",
    "        \n",
    "        # Rename\n",
    "        df.columns = X_var_labels\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Weight-of-Evidence\n",
    "class WoETransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Calculate the WoE\"\"\"\n",
    "    def __init__(self, target, feature):\n",
    "        self.target = target\n",
    "        self.feature = feature\n",
    " \n",
    "    def fit(self, df, y):\n",
    "        \n",
    "        #self.feature = df.drop(['return'],axis = 1).columns.values[0]\n",
    "        df = pd.concat([df,y],axis=1)\n",
    "        #count_values\n",
    "        data = pd.DataFrame()\n",
    "        data['Count'] = df[self.feature].value_counts()               # Count instances of each category, create row for each\n",
    "        data['Bad'] = df.groupby([self.feature])[self.target].sum()   # Count y=1 instances of that category\n",
    "        data['Good'] = data['Count'] - data['Bad']                    # Count y=0 instances of that category\n",
    "        data = data.sort_values(by=[\"Count\"], ascending=False)\n",
    "    \n",
    "        try:\n",
    "            assert data[\"Bad\"].sum() != 0                               # Check that there are y=1 instances in sample\n",
    "            assert data[\"Good\"].sum() != 0                              # Check that there are y=0 instances in sample\n",
    "            assert np.isin(df[self.target].unique(), [0, 1]).all()      # Check that target includes only 0,1 or True,False\n",
    "        except:\n",
    "          print(\"Error: Target must include 2 binary classes.\")\n",
    "          raise     \n",
    "        \n",
    "        #distribution\n",
    "        data[\"WOE_adj\"] = np.log( \n",
    "            ((data[\"Count\"] - data[\"Bad\"] + 0.5) / (data[\"Count\"].sum() - data[\"Bad\"].sum())) / \n",
    "            ((data[\"Bad\"] + 0.5) / data[\"Bad\"].sum())\n",
    "            )\n",
    "        data.replace({\"WOE_adj\": {np.inf: 0, -np.inf: 0}})\n",
    "        self.data = data.sort_values(by=[\"Count\"], ascending=False)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        df.loc[:, self.feature] = df.loc[:, self.feature].map(self.data[\"WOE_adj\"])\n",
    "        return df\n",
    "\n",
    "\n",
    "filter = filter_binary_target(df=df, target=\"return\")\n",
    "\n",
    "filter.auto_filter_binary_target()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessor combinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_pipe = Pipeline([('step_1',WoETransformer(feature = 'item_id', target = 'return')),\n",
    "                      ('step_2',WoETransformer(feature = 'brand_id', target = 'return')),\n",
    "                      ('step_3',WoETransformer(feature = 'user_id', target = 'return')),\n",
    "                      ('step_4',WoETransformer(feature = 'item_size', target = 'return')),\n",
    "                      ('step_5',WoETransformer(feature = 'item_color', target = 'return')),\n",
    "                      ('step_6',WoETransformer(feature = 'user_state', target = 'return'))])\n",
    "\n",
    "\n",
    "std_pipe = Pipeline([('selector', ColumnSelector(['order_age_combine','order_deliver',\n",
    "                                                 'reg_order', 'item_price'])),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "preprocessor = FeatureUnion(transformer_list=[('WoE', woe_pipe),\n",
    "                                              ('Std', std_pipe)])\n",
    "\n",
    "# or\n",
    "numeric_features = list(X.select_dtypes(include=['float32','float64']).columns)\n",
    "categorical_features = list(X.select_dtypes(include=['category']).columns)\n",
    "boolean_features = list(X.select_dtypes(include=['bool']).columns)\n",
    "all_features = numeric_features + categorical_features + boolean_features\n",
    "# I will use OneHotEncoder for the categorical features\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='error', drop='first')\n",
    "# and a MinMaxScaler for the boolean features\n",
    "identity_transformer = MinMaxScaler()\n",
    "\n",
    "# The numeric features I will first impute, then scale and normalize at the end.\n",
    "# Since there are multiple imputing strategies, I define the variablenumeric_imputer_strategy,\n",
    "# which can be set to different values to inspect their influence on the model.\n",
    "# In order to check if centering the values before scaling influences the performance,\n",
    "# I created the variable numeric_standard_scaler_mean.\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy=numeric_imputer_strategy, add_indicator=True)),\n",
    "        ('scaler', StandardScaler(with_mean=numeric_standard_scaler_mean)),\n",
    "        ('normalizer', Normalizer())\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('id', identity_transformer, boolean_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final DataFrame (just an example) and train-test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract target variable and feature matrix \n",
    "X = df.drop(['return'], axis=1)\n",
    "y = df[['return']]\n",
    "\n",
    "# Change the dependent variable from float32 to bool\n",
    "y = y.astype('bool')\n",
    "\n",
    "# Split data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.loc[0:99999,:], y.loc[0:99999,:], test_size=0.3, random_state=888)\n",
    "\n",
    "# Combine X_train and y_train into dataframe\n",
    "Xy_train = pd.concat([X_train, y_train], axis = 1)\n",
    "Xy_test = pd.concat([X_test, y_test], axis = 1)\n",
    "\n",
    "print(\"Remember the shape of our data: \")\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, Xy_train.shape, Xy_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(max_iter=1000, C=1.0, fit_intercept=True)\n",
    "lr_param_grid = {\n",
    "    'preprocessor__num__imputer__metric': ['median', 'mean'],\n",
    "    'preprocessor__num__scaler__method': ['std', 'minmax'],\n",
    "    'select__percentile': [5, 10, 25, 50],\n",
    "    'classifier__C': [0.1, 1.0, 10, 100],\n",
    "    'classifier__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "clf_lr = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        # Select features according to the k highest F-score.\n",
    "        ('select', SelectKBest(score_func=f_regression, k='all')), \n",
    "        ('classifier', model_lr)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# gs_lr = GridSearchCV(estimator=clf_xgb, param_grid=lr_param_grid, scoring='roc_auc', cv=5, verbose=0)\n",
    "# gs_lr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "# ROC Curve\n",
    "y_score = clf_lr.decision_function(X_test)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "# Training data\n",
    "plot_roc_curve(clf_lr, X_train, y_train, color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], \"r--\", color='navy')\n",
    "\n",
    "# Test data\n",
    "plot_roc_curve(clf_lr, X_test, y_test, color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], \"r--\", color='navy')\n",
    "\n",
    "# Confusion matrix\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "# Feature coefficients\n",
    "features = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        # Select features according to a percentile of the highest ANOVA F-value.\n",
    "        ('select', SelectPercentile(score_func=f_classif, percentile=100))\n",
    "    ]\n",
    ")\n",
    "f_lr = features.fit(X_train, y_train)\n",
    "\n",
    "lr_features = []\n",
    "lr_importance = []\n",
    "print(\"Koeffizienten\")\n",
    "for i, n in enumerate(numeric_features + list(clf_lr['preprocessor'].transformers_[1][1].get_feature_names(categorical_features))):\n",
    "    print(f\"{n}: {f_lr[1].pvalues_[i]:.4f}\")\n",
    "    lr_features.append(n)\n",
    "    lr_importance.append(f_lr[1].pvalues_[i])\n",
    "\n",
    "# Present them in a more vivid way\n",
    "# Zip coefficients and names together and make a DataFrame\n",
    "zipped = zip(lr_features, lr_importance)\n",
    "df_lr = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "# Sort the features by the absolute value of their coefficient\n",
    "df_lr[\"abs_value\"] = df_lr[\"value\"].apply(lambda x: abs(x))\n",
    "df_lr[\"colors\"] = df_lr[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "df_lr = df_lr.sort_values(\"abs_value\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"value\",\n",
    "            data=df_lr.head(20),\n",
    "           palette=df_lr.head(20)[\"colors\"]\n",
    "           )\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n",
    "ax.set_title(\"Top 20 Features\", fontsize=25)\n",
    "ax.set_ylabel(\"Coef\", fontsize=22)\n",
    "ax.set_xlabel(\"Feature Name\", fontsize=22)\n",
    "\n",
    "# Gini\n",
    "gini_lr = 100 * (roc_auc * 2 - 1)\n",
    "print(f\"Gini Coefficient of LR: {gini_lr:.2f}%\")\n",
    "\n",
    "# Stability\n",
    "ginis_lr = cross_val_score(clf_lr, X, y, cv=5, scoring='roc_auc')\n",
    "stability_lr = 100 * (np.mean(ginis_lr) * 2 - 1)\n",
    "print(\n",
    "    f\"Mean Gini Coefficient: {stability_lr:.2f}% with standard deviation of {100 * np.std(ginis_lr):.2f}%\"\n",
    ")\n",
    "\n",
    "# F1 Score\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='binary')\n",
    "f1_lr\n",
    "\n",
    "# Brier Score\n",
    "brier_lr = brier_score_loss(y_test, y_pred_lr)\n",
    "brier_lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I use WoE, a copy of train and test data is necessary for further construction\n",
    "Known_Xtrain = X.loc[0:99999,:]\n",
    "Known_ytrain = y.loc[0:99999,:]\n",
    "\n",
    "Unknown_test = X.loc[100000:149999,:]\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=888, max_samples = 0.5,\n",
    "                           max_features = 1, n_estimators = 500)  \n",
    "\n",
    "# Package the preprocessor and model\n",
    "pipe_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                    ('step_drop',DropColumns(drop_list = [19,20,21,22])),\n",
    "                      ('model', rf)])\n",
    "\n",
    "Known_Xtrain1 = Known_Xtrain.copy()\n",
    "Known_ytrain1 = Known_ytrain.copy()\n",
    "Unknown_test1= Unknown_test.copy()\n",
    "\n",
    "pipe_rf.fit(Known_Xtrain1, Known_ytrain1)\n",
    "\n",
    "pred_unknown =pipe_rf.predict_proba(Unknown_test1)[:, 1]\n",
    "\n",
    "predictions = pd.Series(pred_unknown, index=df_unknown.index, name='return') \n",
    "predictions.to_csv('example_predictions_rf.csv') #0.73525\n",
    "\n",
    "# Or only dummies\n",
    "# clf_rf = Pipeline(\n",
    "#     steps=[\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('select', SelectKBest(score_func=f_regression, k='all')),\n",
    "#         ('classifier', RandomForestClassifier(\n",
    "#             max_depth=5, max_features=13, n_estimators=200, min_samples_leaf=15, max_samples = 0.5\n",
    "#         ))\n",
    "#     ]\n",
    "# )\n",
    "# print('Tuning random forest classifier')\n",
    "# # Define meta-parameter grid of candidate settings\n",
    "# param_grid = {'classifier__n_estimators': [200],\n",
    "#               'classifier__max_features': [3, 13, 15],\n",
    "#               'classifier__max_depth': [5, 6],\n",
    "#               'classifier__min_samples_leaf': [5, 10, 15]\n",
    "#               }\n",
    "\n",
    "# # Set up the grid object specifying the tuning options\n",
    "# gs_rf = GridSearchCV(clf_rf, param_grid, cv=5, scoring='roc_auc', verbose=1)\n",
    "# gs_rf.fit(X_train, y_train.values.ravel())\n",
    "# gs_rf.best_params_\n",
    "\n",
    "clf_rf = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('select', SelectKBest(score_func=f_regression, k='all')),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            max_depth=6, max_features=13, n_estimators=200, min_samples_leaf=20, max_samples = 0.8\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "%%time\n",
    "clf_rf.fit(X_train, y_train)\n",
    "print(\"Score training: %0.4f\" % clf_rf.score(X_train, y_train))\n",
    "print(\"Score test: %0.4f\" % clf_rf.score(X_test, y_test))\n",
    "\n",
    "fp_rate_rf, tp_rate_rf, _ = roc_curve(y_test, clf_rf.predict_proba(X_test)[:, 1])\n",
    "print('RF test set AUC with optimal meta-parameters: {:.4f}'.format(auc(fp_rate_rf, tp_rate_rf) ))\n",
    "# ROC Curve\n",
    "auc_rf = auc(fp_rate_rf, tp_rate_rf)\n",
    "# Training data\n",
    "plot_roc_curve(clf_rf, X_train, y_train, color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], \"r--\", color='navy')\n",
    "\n",
    "# Test data\n",
    "plot_roc_curve(clf_rf, X_test, y_test, color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], \"r--\", color='navy')\n",
    "\n",
    "# Confusion matrix\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "# Feature Importance\n",
    "rf_importance  = clf_rf.steps[2][1].feature_importances_\n",
    "\n",
    "# Present them in a more vivid way\n",
    "# Zip coefficients and names together and make a DataFrame\n",
    "zipped = zip(all_features, rf_importance)\n",
    "df_rf = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "# Sort the features by df_rf absolute value of their coefficient\n",
    "df_rf[\"abs_value\"] = df_rf[\"value\"].apply(lambda x: abs(x))\n",
    "df_rf[\"colors\"] = df_rf[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "df_rf = df_rf.sort_values(\"abs_value\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"value\",\n",
    "            data=df_rf.head(20),\n",
    "           palette=df_rf.head(20)[\"colors\"]\n",
    "           )\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n",
    "ax.set_title(\"Top Features\", fontsize=25)\n",
    "ax.set_ylabel(\"Coef\", fontsize=22)\n",
    "ax.set_xlabel(\"Feature Name\", fontsize=22)\n",
    "\n",
    "# Gini\n",
    "gini_rf = 100 * (auc(fp_rate_rf, tp_rate_rf) * 2 - 1)\n",
    "print(f\"Gini Coefficient of RF: {gini_rf:.2f} % \")\n",
    "\n",
    "# Stability\n",
    "ginis_rf = cross_val_score(clf_rf, X, y, cv=5, scoring='roc_auc')\n",
    "stability_rf = 100 * (np.mean(ginis_rf) * 2 - 1)\n",
    "print(\n",
    "    f\"Mean Gini Coefficient: {stability_rf:.2f}% with standard deviation of {100 * np.std(ginis_rf):.2f}%\"\n",
    ")\n",
    "\n",
    "# F1 Score\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='binary')\n",
    "f1_rf\n",
    "\n",
    "# Brier Score\n",
    "brier_rf = brier_score_loss(y_test, y_pred_rf)\n",
    "brier_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBClassifier(\n",
    "            colsample_bytree=0.6,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=3, #15\n",
    "            n_estimators=200,# 30, 300\n",
    "            use_label_encoder=False, \n",
    "            eval_metric='auc')\n",
    "xgb_param_grid = {\n",
    "    'classifier__colsample_bytree': np.linspace(0.5, 0.9, 5),  \n",
    "    'classifier__n_estimators': [100, 200, 250, 300], \n",
    "    'classifier__max_depth': [5, 10, 15, 20], \n",
    "    'classifier__learning_rate': [0.1, 0.01, 0.03],  \n",
    "    'classifier__early_stopping_rounds': [10]\n",
    "} \n",
    "\n",
    "clf_xgb = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('select', SelectKBest(score_func=f_regression, k='all')),\n",
    "        ('classifier', model_xgb)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# gs_xgb = GridSearchCV(estimator=clf_xgb, param_grid=xgb_param_grid, scoring='roc_auc', cv=5, verbose=0)\n",
    "# gs_xgb.fit(X_train, y_train.values.ravel())\n",
    "# print(\"Optimal XGB meta-parameters:\")\n",
    "# print(gs_xgb.best_params_)\n",
    "%%time\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "eval_set = [(clf_xgb.named_steps['preprocessor'].transform(X_test), y_test)]\n",
    "print(\"Score training: %0.4f\" % clf_xgb.score(X_train, y_train))\n",
    "print(\"Score test: %0.4f\" % clf_xgb.score(X_test, y_test))\n",
    "\n",
    "fp_rate_xgb, tp_rate_xgb, _ = roc_curve(y_test, clf_xgb.predict_proba(X_test)[:, 1])\n",
    "print('XGB test set AUC with optimal meta-parameters: {:.4f}'.format(auc(fp_rate_xgb, tp_rate_xgb) ))\n",
    "\n",
    "# ROC Curve\n",
    "auc_xgb = auc(fp_rate_xgb, tp_rate_xgb)\n",
    "# Training data\n",
    "plot_roc_curve(clf_xgb, X_train, y_train, color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], \"r--\", color='navy')\n",
    "\n",
    "# Test data\n",
    "plot_roc_curve(clf_xgb, X_test, y_test, color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], \"r--\", color='navy')\n",
    "\n",
    "# Confusion matrix\n",
    "y_pred_xgb = clf_xgb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "# Feature Importance\n",
    "score_dict_xgb = clf_xgb.named_steps['classifier'].get_booster().get_score(importance_type=\"gain\")\n",
    "xgb_importance  = clf_xgb.steps[2][1].feature_importances_\n",
    "\n",
    "# Present them in a more vivid way\n",
    "# Zip coefficients and names together and make a DataFrame\n",
    "zipped = zip(all_features, xgb_importance)\n",
    "df_xgb = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "# Sort the features by df_xgb absolute value of their coefficient\n",
    "df_xgb[\"abs_value\"] = df_xgb[\"value\"].apply(lambda x: abs(x))\n",
    "df_xgb[\"colors\"] = df_xgb[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "df_xgb = df_xgb.sort_values(\"abs_value\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"value\",\n",
    "            data=df_xgb.head(20),\n",
    "           palette=df_xgb.head(20)[\"colors\"]\n",
    "           )\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n",
    "ax.set_title(\"Top 20 Features\", fontsize=25)\n",
    "ax.set_ylabel(\"Coef\", fontsize=22)\n",
    "ax.set_xlabel(\"Feature Name\", fontsize=22)\n",
    "\n",
    "# Gini\n",
    "gini_xgb = 100 * (auc(fp_rate_xgb, tp_rate_xgb) * 2 - 1)\n",
    "print(f\"Gini Coefficient of XGB: {gini_xgb:.2f} % \")\n",
    "\n",
    "# Stability\n",
    "ginis_xgb = cross_val_score(clf_xgb, X, y, cv=5, scoring='roc_auc')\n",
    "stability_xgb = 100 * (np.mean(ginis_xgb) * 2 - 1)\n",
    "print(\n",
    "    f\"Mean Gini Coefficient: {stability_xgb:.2f}% with standard deviation of {100 * np.std(ginis_xgb):.2f}%\"\n",
    ")\n",
    "\n",
    "# F1 Score\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average='binary')\n",
    "f1_xgb\n",
    "\n",
    "# Brier Score\n",
    "brier_xgb = brier_score_loss(y_test, y_pred_xgb)\n",
    "brier_xgb\n",
    "\n",
    "# Model Explainablity\n",
    "X_test_shap_xgb = clf_xgb.named_steps['preprocessor'].transform(X_test)\n",
    "shap_values_xgb = shap.TreeExplainer(clf_xgb.named_steps['classifier']).shap_values(X_test_shap_xgb)\n",
    "shap.summary_plot(shap_values_xgb, X_test_shap_xgb)\n",
    "\n",
    "vals = np.abs(shap_values_xgb).mean(0)\n",
    "feature_importance = pd.DataFrame(list(zip(X_train.columns,vals)),columns=['col_name','feature_importance_vals'])\n",
    "feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WoE version\n",
    "X_train1 = X_train.copy()\n",
    "y_train1 = y_train.copy()\n",
    "X_test1 = X_test.copy()\n",
    "y_test1 = y_test.copy()\n",
    "\n",
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                         is_unbalance = True,\n",
    "                         metric = 'binary_logloss,auc',\n",
    "                         learning_rate = 0.08,\n",
    "                         max_depth = 6,\n",
    "                         num_leaves = 40,\n",
    "                         feature_fraction = 0.5,\n",
    "                         min_child_samples=19,\n",
    "                         min_child_weight=0.001,\n",
    "                         bagging_fraction = 0.9,\n",
    "                         bagging_freq = 1,\n",
    "                         reg_alpha = 0.005,\n",
    "                         reg_lambda = 5,\n",
    "                         cat_smooth = 0,\n",
    "                         num_iterations = 150, \n",
    "                        )\n",
    "\n",
    "# Package the preprocessor and model\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                    ('step_drop',DropColumns(drop_list = [19,20,21,22])),\n",
    "                      ('model', gbm)])\n",
    "\n",
    "parameters = {\n",
    "    'model__learning_rate' : [0.08,0.09,0.1],\n",
    "    'model__num_iterations': [150,200,210],\n",
    "}\n",
    "\n",
    "\n",
    "gsearch = GridSearchCV(estimator=pipe, param_grid=parameters, scoring='roc_auc', cv=5)\n",
    "gsearch.fit(X_train1, y_train1)\n",
    "\n",
    "# Evaluate the result of model tunning\n",
    "print('Optimal LGB meta-parameters:{0}'.format(gsearch.best_params_))\n",
    "print('Best CV AUC: %0.4f' % gsearch.best_score_)\n",
    "print(gsearch.cv_results_['mean_test_score'])\n",
    "print(gsearch.cv_results_['params'])\n",
    "\n",
    "# Find test set AUC of the best XGB classifier\n",
    "fp_rate, tp_rate, _ = metrics.roc_curve(y_test1, gsearch.predict_proba(X_test1)[:, 1])\n",
    "print('XGB test set AUC with optimal meta-parameters: {:.4f}'.format(metrics.auc(fp_rate, tp_rate) ))\n",
    "\n",
    "# Or only use dummies\n",
    "clf_lgb = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('select', SelectKBest(score_func=f_regression, k='all')),\n",
    "        ('classifier', \n",
    "             lgb.LGBMClassifier(\n",
    "#                 boosting_type='dart', max_depth=5,\n",
    "#                 # reg_alpha=5\n",
    "#                 reg_lambda=0,\n",
    "                importance_type='gain'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "%%time\n",
    "clf_lgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Score training: %0.4f\" % clf_lgb.score(X_train, y_train))\n",
    "print(\"Score test: %0.4f\" % clf_lgb.score(X_test, y_test))\n",
    "\n",
    "fp_rate_lgb, tp_rate_lgb, _ = roc_curve(y_test, clf_lgb.predict_proba(X_test)[:, 1])\n",
    "print('LGBM test set AUC with optimal meta-parameters: {:.4f}'.format(auc(fp_rate_lgb, tp_rate_lgb)))\n",
    "\n",
    "# ROC Curve\n",
    "auc_lgb = auc(fp_rate_lgb, tp_rate_lgb)\n",
    "# Training data\n",
    "plot_roc_curve(clf_lgb, X_train, y_train, color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], \"r--\", color='navy')\n",
    "\n",
    "# Test data\n",
    "plot_roc_curve(clf_lgb, X_test, y_test, color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], \"r--\", color='navy');\n",
    "\n",
    "# Confusion matrix\n",
    "y_pred_lgb = clf_lgb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_lgb)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "# Feature Importance\n",
    "lgb_importance  = clf_lgb.steps[2][1].feature_importances_\n",
    "\n",
    "# Present them in a more vivid way\n",
    "# Zip coefficients and names together and make a DataFrame\n",
    "zipped = zip(all_features, lgb_importance)\n",
    "df_lgb = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "# Sort the features by df_lgb absolute value of their coefficient\n",
    "df_lgb[\"abs_value\"] = df_lgb[\"value\"].apply(lambda x: abs(x))\n",
    "df_lgb[\"colors\"] = df_lgb[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "df_lgb = df_lgb.sort_values(\"abs_value\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"value\",\n",
    "            data=df_lgb.head(20),\n",
    "           palette=df_lgb.head(20)[\"colors\"]\n",
    "           )\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n",
    "ax.set_title(\"Top Features\", fontsize=25)\n",
    "ax.set_ylabel(\"Coef\", fontsize=22)\n",
    "ax.set_xlabel(\"Feature Name\", fontsize=22)\n",
    "\n",
    "# Gini\n",
    "gini_lgb = (auc(fp_rate_lgb, tp_rate_lgb) * 2 - 1) * 100\n",
    "print(f\"Gini Coefficient of LightGBM: {gini_lgb:.2f} % \")\n",
    "\n",
    "# Stability\n",
    "ginis_lgb = cross_val_score(clf_lgb, X, y, cv=5, scoring='roc_auc')\n",
    "stability_lgb = 100 * (np.mean(ginis_lgb) * 2 - 1)\n",
    "print(\n",
    "    f\"Mean Gini Coefficient: {stability_lgb:.2f}% with standard deviation of {100 * np.std(ginis_lgb):.2f}%\"\n",
    ")\n",
    "# F1 Score\n",
    "f1_lgb = f1_score(y_test, y_pred_lgb, average='binary')\n",
    "f1_lgb\n",
    "\n",
    "# Brier Score\n",
    "brier_lgb = brier_score_loss(y_test, y_pred_lgb)\n",
    "brier_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_overview_df = pd.DataFrame([[auc_lr, gini_lr, stability_lr, f1_lr, brier_lr], [auc_xgb, gini_xgb, stability_xgb, f1_xgb, brier_xgb], [auc_rf, gini_rf, stability_rf, f1_rf, brier_rf], [auc_lgb, gini_lgb, stability_lgb, f1_lgb, brier_lgb]], columns=['AUC', 'Gini', 'Stability', 'F1 Score', 'Brier Score'], index=[\"LR\", \"XGB\", \"RF\", \"LGBM\"])\n",
    "model_overview_df['AUC'] = model_overview_df['AUC']*100\n",
    "model_overview_df['F1 Score'] = model_overview_df['F1 Score']*100\n",
    "model_overview_df['Brier Score'] = model_overview_df['Brier Score']*100\n",
    "model_overview_df.round(decimals=2)\n",
    "\n",
    "#model_overview_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
